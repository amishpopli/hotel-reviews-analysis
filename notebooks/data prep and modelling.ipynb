{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cardiac-wallpaper",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "synthetic-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, preprocessing, ensemble, metrics\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-listening",
   "metadata": {},
   "source": [
    "# Read dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "photographic-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('../datasets/hotel_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-distinction",
   "metadata": {},
   "source": [
    "# Extract columns required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tropical-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = reviews[['reviews_rating', 'reviews_text', 'reviews_title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-combat",
   "metadata": {},
   "source": [
    "# Remove nulls - Atleast one of title and review should have a value and rating should not be null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cognitive-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = modeling_data[((modeling_data.reviews_text.notnull())|(modeling_data.reviews_title.notnull()))\\\n",
    "                             &(modeling_data.reviews_rating.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "guided-bailey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-collapse",
   "metadata": {},
   "source": [
    "# remove punctuation, convert to lowercase, remove stop words and do lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "false-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    if type(text) == float:\n",
    "        return \"\"\n",
    "    else:\n",
    "        nopunc = [i.lower() for i in text if (i not in string.punctuation)&(i.isdigit()==False)]\n",
    "        nopunc_text = ''.join(nopunc)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        nonpunc_nonstopwords_lemma_text = [lemmatizer.lemmatize(i) for i in nopunc_text.split() if i not in stopwords.words('english')]\n",
    "        text = \" \".join(nonpunc_nonstopwords_lemma_text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-tuning",
   "metadata": {},
   "source": [
    "# Transform columns reviews_text and reviews_title using the function text_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "convinced-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data['reviews_text'] = modeling_data.apply(lambda row: text_process(row['reviews_text']), axis=1)\n",
    "modeling_data['reviews_title'] = modeling_data.apply(lambda row: text_process(row['reviews_title']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-keyboard",
   "metadata": {},
   "source": [
    "# Build scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "greatest-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(preds,true):\n",
    "    accuracy = {\n",
    "            'mae' : np.round(metrics.mean_absolute_error(true, preds),2),\n",
    "    'rmse': np.round(metrics.mean_squared_error(true, preds),2),\n",
    "    'mape':np.round(metrics.mean_absolute_percentage_error(true, preds),2),\n",
    "    }\n",
    "    return accuracy\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-budapest",
   "metadata": {},
   "source": [
    "# Bag of words - baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pressing-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(modeling_data.apply(lambda x: x['reviews_text']+' '+x['reviews_title'], axis=1), columns = ['text'])\n",
    "vectorizer_bow = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "trained_bow_transformer = vectorizer_bow.fit(train_data['text'])\n",
    "\n",
    "train_data = trained_bow_transformer.transform(train_data['text'])\n",
    "\n",
    "train_data.columns =  trained_bow_transformer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-navigation",
   "metadata": {},
   "source": [
    "# Train bow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "residential-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = modeling_data['reviews_rating'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "psychological-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(train_data, y, test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "southwest-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bow = ensemble.RandomForestRegressor(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "challenging-vermont",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "worldwide-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_bow.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "monetary-capital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.67, 'rmse': 0.77, 'mape': 0.26}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-cliff",
   "metadata": {},
   "source": [
    "# TFIDF (advanced bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spoken-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(modeling_data.apply(lambda x: x['reviews_text']+' '+x['reviews_title'], axis=1), columns = ['text'])\n",
    "vectorizer_tfidf = feature_extraction.text.TfidfVectorizer(ngram_range=(1,2), max_df=0.9)\n",
    "\n",
    "trained_tf_idf_transformer = vectorizer_tfidf.fit(train_data['text'])\n",
    "\n",
    "train_data = trained_tf_idf_transformer.transform(train_data['text'])\n",
    "\n",
    "train_data.columns =  trained_tf_idf_transformer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-digest",
   "metadata": {},
   "source": [
    "# Train TFIDF model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "false-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = modeling_data['reviews_rating'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "south-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(train_data, y, test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "solid-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfidf = ensemble.RandomForestRegressor(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "defined-invite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tfidf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wrong-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_tfidf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "intelligent-orientation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.68, 'rmse': 0.79, 'mape': 0.26}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-contamination",
   "metadata": {},
   "source": [
    "# Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "entire-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving bow forest model\n",
    "with open('../models/model_bow.pkl', 'wb') as file:\n",
    "    pickle.dump(model_bow, file)\n",
    "    \n",
    "# saving bow vectorizer\n",
    "with open('../models/transformer_bow.pkl', 'wb') as file:\n",
    "    pickle.dump(trained_bow_transformer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "knowing-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving tfidf forest model\n",
    "with open('../models/model_tfidf.pkl', 'wb') as file:\n",
    "    pickle.dump(model_tfidf, file)\n",
    "    \n",
    "# saving tfidf vectorizer\n",
    "with open('../models/transformer_tfidf.pkl', 'wb') as file:\n",
    "    pickle.dump(trained_tf_idf_transformer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-huntington",
   "metadata": {},
   "source": [
    "# Conclusion - \n",
    "\n",
    "we dont see a major jump in accuracy metrics by changing the underlying models. Even though it was expected TFIDF to improve the accuracy, I believe due to the increase in the number of sparse features, our accuracy went down a bit (curse of dimensionality)\n",
    "\n",
    "As next steps, we can try more advanced encodings like:\n",
    "1- word2vec\n",
    "2- BERT\n",
    "\n",
    "Due to long training times, I am not building these at the momemt \n",
    "\n",
    "Also I have only used random forest model since it is the quickest to train\n",
    "\n",
    "We can also try models like naive bayes in the future\n",
    "\n",
    "I believe if we were to change the output variable from a continuious variable to a categorical avariable like ratings less than 1, rating between 1 and 2 and so on, we can expect a significant jump in accuracy. Since this was not in scope of our problem, I did not try it\n",
    "\n",
    "Moving on, we will deploy our 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyamish",
   "language": "python",
   "name": "pyamish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
